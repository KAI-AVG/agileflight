{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import rospy\n",
    "from std_msgs.msg import Empty, String, Header\n",
    "from geometry_msgs.msg import Vector3, TwistStamped\n",
    "from sensor_msgs.msg import Image\n",
    "from dodgeros_msgs.msg import Command, QuadState\n",
    "from envsim_msgs.msg import ObstacleArray, Obstacle\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import message_filters\n",
    "# from rl_example import load_rl_policy\n",
    "from user_code import compute_command_state_based\n",
    "from utils import AgileCommandMode, AgileQuadState, AgileCommand\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "from os.path import join as opj\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "base_path2=os.environ.get(\"project_path\")\n",
    "SMALL_EPS = 1e-5\n",
    "sys.path.append(opj(base_path2,'learner')) # type: ignore\n",
    "from base_model import *\n",
    "from policy_model import LSTMNetVIT\n",
    "sys.path.append(opj(base_path2,'utils')) # type: ignore\n",
    "from logger import Logger\n",
    "from ev_utils import * \n",
    "from omegaconf import OmegaConf,DictConfig\n",
    "import esim_torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgilePilotNode:\n",
    "    def __init__(self,config:DictConfig):\n",
    "        self.logger=Logger(name=\"RUN\")\n",
    "        self.logger.info(\"Initializing agile_pilot_node...\")\n",
    "        rospy.init_node(\"agile_pilot_node\", anonymous=False)\n",
    "        self.config=config\n",
    "        self.resize_input=config.run.resize_input\n",
    "        self.data_buffer_maxlength =config.run.data_buffer_maxlength\n",
    "        self.run_expert_in_parallel = config.run.run_expert_in_parallel\n",
    "        self.exp_name = config.exp_name\n",
    "        self.total_num_exps = config.total_num_exps\n",
    "        self.desiredVel=config.run.desiredVel\n",
    "        self.target=config.target\n",
    "        self.mode = config.mode\n",
    "        assert self.mode == 'vision' or self.mode =='expert'\n",
    "        self.do_events = self.mode ==\"vision\"\n",
    "        self.plot_cmd = False\n",
    "        self.extras = None\n",
    "        #######################\n",
    "\n",
    "        ########################################\n",
    "        ## Set up NN and other configurations ##\n",
    "        ########################################\n",
    "\n",
    "\n",
    "        # load yaml of parameters\n",
    "        with open(opj(base_path2,'envsim/parameters/simple_sim_pilot.yaml')) as file: # type: ignore\n",
    "            pilot_params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "            self.takeoff_height = pilot_params['takeoff_height']\n",
    "\n",
    "        with open(opj(base_path2,'flightmare/flightpy/configs/vision/config.yaml')) as file: # type: ignore\n",
    "            config_params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "            camera_params = config_params['rgb_camera']\n",
    "\n",
    "        self.image_h, self.image_w = (camera_params['height'], camera_params['width'])\n",
    "        # self.gimbal_h, self.gimbal_w = (60, 90)\n",
    "        # self.gimbal_fov = camera_params['fov']\n",
    "        self.publish_commands = False\n",
    "        self.cv_bridge = CvBridge()\n",
    "        self.state = None\n",
    "        self.esim = esim_torch.ESIM(contrast_threshold_neg=0.2,\n",
    "                            contrast_threshold_pos=0.2,\n",
    "                            refractory_period_ns=.5e6) \n",
    "        \n",
    "        quad_name = \"kingfisher\"\n",
    "\n",
    "        # logging\n",
    "        self.init = 0\n",
    "        self.col = 0\n",
    "        self.t1 = 0 #Time flag\n",
    "        self.timestamp = 0 #Time stamp initial\n",
    "        # self.last_valid_im = None #Image that will be logged\n",
    "        self.data_format = {'timestamp':[],\n",
    "                            'desired_vel':[],\n",
    "                            'quat_1':[],\n",
    "                            'quat_2':[],\n",
    "                            'quat_3':[],\n",
    "                            'quat_4':[],\n",
    "                            'pos_x':[],\n",
    "                            'pos_y':[],\n",
    "                            'pos_z':[],\n",
    "                            'vel_x':[],\n",
    "                            'vel_y':[],\n",
    "                            'vel_z':[],\n",
    "                            'velcmd_x':[],\n",
    "                            'velcmd_y':[],\n",
    "                            'velcmd_z':[],\n",
    "                            'ct_cmd':[],\n",
    "                            'br_cmd_x':[],\n",
    "                            'br_cmd_y':[],\n",
    "                            'br_cmd_z':[],\n",
    "                            'is_collide': [],\n",
    "                            }\n",
    "        self.data_buffer = pd.DataFrame(self.data_format) # store in the data frame\n",
    "        self.log_ctr = 0 # counter for the csv, unused for now\n",
    "        # if goal distance is 60, end of data collection xrange is 50\n",
    "        self.data_collection_xrange = [0+5, self.target-.17*self.target]\n",
    "        # make the folder for the epoch\n",
    "        self.folder = opj(base_path2,\"envtest/rollouts\",self.exp_name) # type: ignore\n",
    "        os.makedirs(self.folder,exist_ok=True)\n",
    "        # if this is a named experiment, save the config file to maintain information of run, including scene/env/etc\n",
    "        shutil.copy(opj(base_path2, 'configs/sim_config.yaml'), opj(self.folder, 'simulation_config.yaml')) \n",
    "        shutil.copy(opj(base_path2, 'flightmare/flightpy/configs/vision/config.yaml'), opj(self.folder, 'competition_config.yaml')) \n",
    "        self.events = np.zeros((4,self.image_h, self.image_w))\n",
    "\n",
    "        # if save_events, save each event frame via the log function and then save as a npy\n",
    "        self.evims = []\n",
    "        self.im_dbg2s = []\n",
    "        self.state_poss = []\n",
    "        self.state_vels = []\n",
    "        self.expert_command = None\n",
    "        self.expert_commands = []\n",
    "        self.vision_commands = []\n",
    "        self.spline_poss = []\n",
    "        self.spline_vels = []\n",
    "        self.plotted_commands = False\n",
    "\n",
    "        if self.mode == 'vision':\n",
    "            self.Model=LSTMNetVIT()\n",
    "            model_path = opj(base_path2,\"experiment/models/easy_static_100/best/checkpoint_epoch_50.pth\")\n",
    "            checkpoint = torch.load(model_path)\n",
    "            self.Model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            # if self.checkpoint_path is not None:\n",
    "            #     self.Model.load_from_checkpoint(self.checkpoint_path,self.combine_checkpoints)\n",
    "            self.Model.eval()\n",
    "            # Initialize hidden state\n",
    "            #self.Model.model_hidden_state=[None]\n",
    "            self.logger.info(f\"Model loaded\")\n",
    "        self.start_time = 0\n",
    "        self.logged_time_flag = 0\n",
    "        self.first_data_write = False\n",
    "        self.current_cmd_controller = None\n",
    "        self.current_cmd = None\n",
    "        self.keyboard_input = ''\n",
    "        self.got_keypress = 0.0\n",
    "        # initialize to bogus obstacle array with 10 obstacles at 1000, 1000, 1000\n",
    "        self.obs_msg = self.create_obstacle_array()\n",
    "        # vision member variables\n",
    "        self.depth = np.zeros((self.image_h, self.image_w))\n",
    "        self.depth_t = None\n",
    "        self.depth_im_threshold = 0.9 # increased from 0.1 (max depth seems to be ~ 0.885)\n",
    "        self.im = np.zeros((self.image_h, self.image_w),dtype=np.float32)\n",
    "        self.im_t = 0\n",
    "        self.im_ctr = 0\n",
    "        self.prev_im = np.zeros((self.image_h, self.image_w),dtype=np.float32)\n",
    "\n",
    "        # self.depth_gimbal = np.zeros((self.gimbal_h, self.gimbal_w))\n",
    "        # self.im_gimbal = np.zeros((self.gimbal_h, self.gimbal_w))\n",
    "        # self.prev_im_gimbal = np.zeros((self.gimbal_h, self.gimbal_w))\n",
    "        # self.gimbal = None\n",
    "        self.pts = [[0,0], [0,0], [0,0], [0,0]]\n",
    "        self.im_dbg1 = None\n",
    "        self.im_dbg2 = None\n",
    "        # place to store extras from learned model\n",
    "        self.extras = None\n",
    "        # manual synchronization variables\n",
    "        self.accepted_delta_t_im_depth = 0.01\n",
    "\n",
    "        self.csv_file = base_path2+'/flightmare/flightpy/configs/vision/'+config_params['environment']['level']+'/'+config_params['environment']['env_folder']+'/static_obstacles.csv' # type: ignore\n",
    "        self.is_trees = 'trees' in config_params['environment']['level'] or 'forest' in config_params['environment']['level']\n",
    "\n",
    "        #####################\n",
    "        ## ROS subscribers ##\n",
    "        #####################\n",
    "\n",
    "        # Logic subscribers\n",
    "        self.start_sub = rospy.Subscriber(\n",
    "            \"/\" + quad_name + \"/start_navigation\",\n",
    "            Empty,\n",
    "            self.start_callback,\n",
    "            queue_size=1,\n",
    "            tcp_nodelay=True,\n",
    "        )\n",
    "\n",
    "        # Observation subscribers\n",
    "        # we are making odom, image, and depth approximately time synchronized for logging purposes\n",
    "        self.odom_sub = message_filters.Subscriber(\n",
    "            \"/\" + quad_name + \"/dodgeros_pilot/state\",\n",
    "            QuadState,\n",
    "        )\n",
    "        self.im_sub = message_filters.Subscriber(\n",
    "            \"/\" + quad_name + \"/dodgeros_pilot/unity/image\",\n",
    "            Image,\n",
    "        )\n",
    "        self.depth_sub = message_filters.Subscriber(\n",
    "            \"/\" + quad_name + \"/dodgeros_pilot/unity/depth\",\n",
    "            Image,\n",
    "        )\n",
    "        timesync = message_filters.ApproximateTimeSynchronizer([self.odom_sub, self.im_sub, self.depth_sub], queue_size=10, slop=self.accepted_delta_t_im_depth)\n",
    "        timesync.registerCallback(self.observation_callback)\n",
    "\n",
    "        self.obstacle_sub = rospy.Subscriber(\n",
    "            \"/\" + quad_name + \"/dodgeros_pilot/groundtruth/obstacles\",\n",
    "            ObstacleArray,\n",
    "            self.obstacle_callback,\n",
    "            queue_size=1,\n",
    "            tcp_nodelay=True,\n",
    "        )\n",
    "        self.cmd_sub = rospy.Subscriber(\n",
    "            \"/\" + quad_name + \"/dodgeros_pilot/command\",\n",
    "            Command,\n",
    "            self.cmd_callback,\n",
    "            queue_size=1,\n",
    "            tcp_nodelay=True,\n",
    "        )\n",
    "\n",
    "        ####################\n",
    "        ## ROS publishers ##\n",
    "        ####################\n",
    "\n",
    "        # Command publishers\n",
    "        self.cmd_pub = rospy.Publisher(\n",
    "            \"/\" + quad_name + \"/dodgeros_pilot/feedthrough_command\",\n",
    "            Command,\n",
    "            queue_size=1,\n",
    "        )\n",
    "        self.linvel_pub = rospy.Publisher(\n",
    "            \"/\" + quad_name + \"/dodgeros_pilot/velocity_command\",\n",
    "            TwistStamped,\n",
    "            queue_size=1,\n",
    "        )\n",
    "        self.im_dbg1_pub = rospy.Publisher(\n",
    "            \"/debug_img1\",\n",
    "            Image,\n",
    "            queue_size=1,\n",
    "        )\n",
    "        self.im_dbg2_pub = rospy.Publisher(\n",
    "            \"/debug_img2\",\n",
    "            Image,\n",
    "            queue_size=1,\n",
    "        )\n",
    "        self.logger.info(\"Initialization completed!\")\n",
    "\n",
    "    #############################\n",
    "    ## Vision-based controller ##\n",
    "    #############################\n",
    "\n",
    "    def compute_command_vision_based(self):\n",
    "\n",
    "        # Example of LINVEL command (velocity is expressed in world frame)\n",
    "        command_mode = 2\n",
    "        command = AgileCommand(command_mode)\n",
    "        if self.state is None:\n",
    "            self.logger.error(\"state is None\")\n",
    "        command.t = self.state.t # type: ignore\n",
    "        command.yawrate = 0.0\n",
    "        command.mode = command_mode\n",
    "        \n",
    "        ###############\n",
    "        ## Load data ##\n",
    "        ###############\n",
    "        # determine model input image\n",
    "        evf = torch.tensor(self.events).unsqueeze(0)\n",
    "        # if im is not of size resize_input (see default config file configs/lstm.txt), resize\n",
    "        if tuple(evf.shape[-2:]) != self.resize_input:\n",
    "            evf = torch.nn.functional.interpolate(evf, size=tuple(self.resize_input), mode='bilinear', align_corners=False).float()\n",
    "\n",
    "        # if self.do_events:\n",
    "        #     # set this by the percentile\n",
    "        #     im_scaledown_factor = torch.quantile(torch.abs(im), 0.97)\n",
    "        # else:\n",
    "        #     im_scaledown_factor = 1.0\n",
    "        with torch.no_grad():\n",
    "            x,self.extras = self.Model(evf,self.extras) # input_frame\n",
    "\n",
    "            # hidden state that for combo origunet+X model should be an unraveled iterable of ((origunet_unet_hidden, origunet_velpred_hidden, X_hidden\n",
    "        #self.Model.update_hidden_state(self.extras)\n",
    "        # print(f'[RUN_COMPETITION VISION_BASED] model output {x}')\n",
    "\n",
    "        #x = x.squeeze().detach().numpy()\n",
    "        vx = x.detach().numpy().squeeze(axis=0)\n",
    "        vx = np.clip(x,-1,1)\n",
    "        com = np.array([vx,np.sqrt(1-vx**2),0])\n",
    "        command.velocity = com\n",
    "        # possibly necessary scalers if using a pretrained V(phi) from another environment\n",
    "        # command.velocity[1] *= 2.0\n",
    "\n",
    "        # manual drone acceleration phase\n",
    "        min_xvel_cmd = 1.0\n",
    "        hardcoded_ctl_threshold = 2.0\n",
    "        if self.state.pos[0] < hardcoded_ctl_threshold: # type: ignore\n",
    "            command.velocity[0] = max(min_xvel_cmd, (self.state.pos[0]/hardcoded_ctl_threshold)*self.desiredVel) # type: ignore\n",
    "        \n",
    "        return command\n",
    "\n",
    "    def cmd_callback(self, msg):\n",
    "        self.current_cmd_controller = msg\n",
    "\n",
    "    # legacy\n",
    "    def readVel(self,file):\n",
    "        with open(file,\"r\") as f:\n",
    "            x = f.readlines()\n",
    "            for i in range(len(x)):\n",
    "                if i == 0:\n",
    "                    return float(x[i].split(\"\\n\")[0])\n",
    "    # compute estimated events from two stored images, with thresholds inputted\n",
    "    # network was trained from evims of floats binned by 0.2, so estimate that here\n",
    "    def compute_events(self, neg_thresh=0.2, pos_thresh=0.2, gimbal=False):\n",
    "\n",
    "        im = self.im\n",
    "        prev_im = self.prev_im\n",
    "        h = self.image_h\n",
    "        w = self.image_w\n",
    "    \n",
    "        events_zero = np.zeros((4, h, w))\n",
    "        \n",
    "        if im is None or prev_im is None:\n",
    "            self.events = events_zero\n",
    "            return\n",
    "        \n",
    "        device = torch.device(\"cuda\")\n",
    "        img_seq = np.stack([prev_im,im],axis=0)\n",
    "        log_img = torch.from_numpy(np.log(img_seq.astype(\"float32\") + 1e-10)).to(device)\n",
    "        timestapes=np.array([self.prev_t,self.im_t])\n",
    "        timestamps_ns = torch.from_numpy((timestapes * 1e9).astype(\"int64\")).to(device)\n",
    "        events = self.esim.forward(log_img,timestamps_ns)\n",
    "        ts = events['t']\n",
    "        event_indices = torch.bitwise_and((ts >= self.prev_t), (ts <= self.im_t))\n",
    "        x, y, t, p = torch.stack([events[key][event_indices].unsqueeze(1) for key in ['x', 'y', 't', 'p']], dim=0).unbind(0)\n",
    "        event_window = torch.cat((x,y,t,p),dim=1)\n",
    "        sorted_indices = torch.argsort(event_window[:, 2]) \n",
    "        event_array = event_window[sorted_indices].cpu().numpy()\n",
    "        img_size = (h,w)\n",
    "        evframes = np.zeros((4,*img_size))\n",
    "        if event_array.shape[0]:\n",
    "            t_norm = event_array[-1,2]-event_array[0,2]\n",
    "            event_array[:,2] = event_array[:,2]/t_norm*5\n",
    "        else:\n",
    "            self.events = events_zero\n",
    "            return\n",
    "        pos_indices = event_array[:, 3] > 0\n",
    "        neg_indices = ~pos_indices\n",
    "        # 处理正负极性事件\n",
    "        evframes[0, event_array[pos_indices, 1].astype(int), event_array[pos_indices, 0].astype(int)] += 1\n",
    "        evframes[2, event_array[pos_indices, 1].astype(int), event_array[pos_indices, 0].astype(int)] = event_array[pos_indices, 2]\n",
    "        evframes[1, event_array[neg_indices, 1].astype(int), event_array[neg_indices, 0].astype(int)] += 1\n",
    "        evframes[3, event_array[neg_indices, 1].astype(int), event_array[neg_indices, 0].astype(int)] = event_array[neg_indices, 2]\n",
    "        \n",
    "        self.events = evframes\n",
    "        # approximation of events calculation\n",
    "\n",
    "        # difflog = np.log(im + SMALL_EPS) - np.log(prev_im + SMALL_EPS)\n",
    "\n",
    "        # # thresholding\n",
    "        # self.events = np.zeros_like(difflog)\n",
    "\n",
    "        # if np.abs(difflog).max() < max(pos_thresh, neg_thresh):\n",
    "        #     return\n",
    "\n",
    "        # # quantize difflog by thresholds\n",
    "        # pos_idxs = np.where(difflog > 0.0)\n",
    "        # neg_idxs = np.where(difflog < 0.0)\n",
    "        # self.events[pos_idxs] = (difflog[pos_idxs] // pos_thresh) * pos_thresh\n",
    "        # self.events[neg_idxs] = (difflog[neg_idxs] // -neg_thresh) * -neg_thresh\n",
    "        return\n",
    "\n",
    "    # approximate time-synced callback with three sensor measurements: odom state, rgb image, depth image\n",
    "    def observation_callback(self, odom_msg, im_msg, depth_msg):\n",
    "\n",
    "        ###################\n",
    "        ### SUBSCRIBERS ###\n",
    "        ###################\n",
    "\n",
    "        # handle odom\n",
    "        self.state_callback(odom_msg)\n",
    "\n",
    "        # handle image\n",
    "        if self.im_callback(im_msg) < 0:\n",
    "            return\n",
    "\n",
    "        # handle depth\n",
    "        if self.depth_callback(depth_msg) < 0:\n",
    "            return\n",
    "\n",
    "        ###################\n",
    "        \n",
    "        # run expert regardless of method\n",
    "        if self.mode == 'expert':\n",
    "        \n",
    "            self.expert_command, extras = compute_command_state_based(\n",
    "                state=self.state,\n",
    "                obstacles=self.obs_msg,\n",
    "                desiredVel=self.desiredVel,\n",
    "                is_trees=self.is_trees,\n",
    "                logger=self.logger\n",
    "            )\n",
    "            collisions = extras['collisions']\n",
    "            wpt_idx = extras['wpt_idx']\n",
    "            spline_poss = extras['spline_poss']\n",
    "            spline_vels = extras['spline_vels']\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.expert_command = None\n",
    "            collisions = None\n",
    "            wpt_idx = None\n",
    "            spline_poss = None\n",
    "            spline_vels = None\n",
    "\n",
    "        # debug image 2; changeable debug image\n",
    "        self.im_dbg2 = self.im.copy() # copying full image\n",
    "        \n",
    "        # if im_dgb2 is single-channel, make 3-channel\n",
    "        if len(self.im_dbg2.shape) == 2:\n",
    "            self.im_dbg2 = cv2.cvtColor((self.im_dbg2*255).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "            # self.im_dbg2 = np.stack((self.im_dbg2,)*3, axis=-1)\n",
    "\n",
    "        # if in vision command mode, compute vision command and publish\n",
    "        vision_command = None\n",
    "        if self.mode == 'vision':\n",
    "\n",
    "            start_compute_time = time.time()\n",
    "            vision_command = self.compute_command_vision_based()\n",
    "\n",
    "            # useful occasional prints for debugging\n",
    "            # if self.im_ctr % 20 == 0:\n",
    "            #     self.logger.debug(f'compute_command_vision_based took {time.time() - start_compute_time:.3f} seconds')\n",
    "            #     self.logger.debug(f'events min = {self.events.min():.2f}, events max = {self.events.max():.2f}, events 0.97 quantile = {torch.quantile(torch.abs(torch.Tensor(self.events)), 0.97):.2f}')\n",
    "\n",
    "            #     self.logger.debug(f'depth min = {self.extras[0].min():.2f}, depth max = {self.extras[0].max():.2f}, depth 0.97 quantile = {torch.quantile(torch.abs(self.extras[0]), 0.97):.2f}')\n",
    "\n",
    "            # if UNet type model, visualize the first element of extras which is fully interpolated up-to-size depth prediction from evframe\n",
    "            # if self.Model.model_name == 'OrigUNet' or \\\n",
    "            # (isinstance(self.model_type, list) and self.model_type[0] == 'OrigUNet' and self.model_type[1] == 'VITFLY_ViTLSTM') or \\\n",
    "            # (isinstance(self.model_type, list) and self.model_type[0] == 'OrigUNet' and self.model_type[1] == 'ConvNet_w_VelPred'):\n",
    "                \n",
    "            #     self.im_dbg2 = (np.stack((self.extras[0].squeeze().detach().numpy(),)*3, axis=-1) * 255).astype(np.uint8)\n",
    "            \n",
    "            # self.im_dbg2_pub.publish(self.cv_bridge.cv2_to_imgmsg(self.im_dbg2, encoding=\"passthrough\"))\n",
    "\n",
    "            self.command = vision_command\n",
    "\n",
    "        # if in state mode, compute state command and publish\n",
    "        else:\n",
    "\n",
    "            # user_code expert\n",
    "            self.command = self.expert_command\n",
    "\n",
    "            # debug image 2 will overlay the collision array of points as white dots,\n",
    "            # where if collision[i, j] == 1 it is red,\n",
    "            # and the wpt_idx as a green dot\n",
    "            if collisions is not None:\n",
    "                x_px_offset = self.im_dbg2.shape[1] / (collisions.shape[1]+1) # float\n",
    "                y_px_offset = self.im_dbg2.shape[0] / (collisions.shape[0]+1) # float\n",
    "                # collisions array goes from physical top left (body frame y=15, z=15) to bottom left\n",
    "                # coordinates in waypoint frame\n",
    "                for yi in range(collisions.shape[0]):\n",
    "\n",
    "                    for xi in range(collisions.shape[1]):\n",
    "\n",
    "                        if collisions[yi, xi] == 1:\n",
    "                            color = (0, 0, 255) # red\n",
    "                        else:\n",
    "                            color = (255, 0, 0) # blue\n",
    "                        pt_in = (int((xi+1)*x_px_offset), int((yi+1)*y_px_offset))\n",
    "                        self.im_dbg2 = cv2.circle(self.im_dbg2, pt_in, 2, color, -1)\n",
    "\n",
    "                # mark chosen waypoint with green circle\n",
    "                if wpt_idx is not None:\n",
    "                    pt_in_chosen = (int((wpt_idx[1]+1)*x_px_offset), int((wpt_idx[0]+1)*y_px_offset))\n",
    "                    cv2.circle(self.im_dbg2, pt_in_chosen, 6, (0, 255, 0), -1)\n",
    "\n",
    "        self.publish_command(self.command)\n",
    "\n",
    "        # publish debug images\n",
    "        # debug image 1; image and events overlayed + velocity command arrow\n",
    "\n",
    "        im_dbg1 = self.depth.copy() if not self.do_events else self.im.copy()\n",
    "        h, w = self.image_h, self.image_w\n",
    "\n",
    "        # if self.do_events:\n",
    "\n",
    "        #     im_dbg1_evs, enc = simple_evim(self.events, scaledown_percentile=.8, style='redblue-on-black') # copying cropped and horizon-aligned image\n",
    "        #     # add in image for better visualization\n",
    "        #     im_dbg1 = np.stack(((im_dbg1*255.0).astype(np.uint8),)*3, axis=-1)\n",
    "        #     if self.events is not None:\n",
    "        #         im_dbg1[np.where(self.events != 0.0)] = im_dbg1_evs[np.where(self.events != 0.0)]\n",
    "\n",
    "        arrow_start = (w//2, h//2)\n",
    "        if not self.vision_based and wpt_idx is not None:\n",
    "            arrow_end = pt_in_chosen\n",
    "        else:\n",
    "            arrow_end = (int(w/2-self.command.velocity[1]*(w/3)), int(h/2-self.command.velocity[2]*(h/3)))\n",
    "        \n",
    "        self.im_dbg1 = im_dbg1\n",
    "        # self.im_dbg1 = cv2.arrowedLine( im_dbg1, arrow_start, arrow_end, (0, 0, 0), h//60, tipLength=0.2)\n",
    "        self.im_dbg1_pub.publish(self.cv_bridge.cv2_to_imgmsg(self.im_dbg1, encoding=\"passthrough\"))\n",
    "\n",
    "        self.im_dbg2 = cv2.arrowedLine( self.im_dbg2, arrow_start, arrow_end, (0, 0, 0), h//80, tipLength=0.15)\n",
    "        self.im_dbg2_pub.publish(self.cv_bridge.cv2_to_imgmsg(self.im_dbg2, encoding=\"bgr8\"))\n",
    "\n",
    "        # under some conditions, log sensor data\n",
    "        # state, image, and depth image\n",
    "        if self.state is not None and self.state.pos[0] > self.data_collection_xrange[0] and self.state.pos[0] < self.data_collection_xrange[1]:\n",
    "            self.log_data(log_expert=self.run_expert_in_parallel)\n",
    "            self.plotted_commands = False\n",
    "            self.expert_commands.append(self.expert_command)\n",
    "            self.vision_commands.append(vision_command)\n",
    "            self.spline_poss.append(spline_poss)\n",
    "            self.spline_vels.append(spline_vels)\n",
    "            self.state_vels.append(self.state.vel)\n",
    "            self.state_poss.append(self.state.pos)\n",
    "\n",
    "        # once the drone is beyond the collection range, save a plot of expert and vision commands\n",
    "        if self.state is not None and self.state.pos[0] > self.data_collection_xrange[1] and not self.plotted_commands and self.plot_cmd:\n",
    "\n",
    "            self.logger.debug(f'Plotting commands...')\n",
    "\n",
    "            from matplotlib import pyplot as plt\n",
    "            fig, axs = plt.subplots(3, 2, figsize=(8, 8))\n",
    "\n",
    "            axs[0, 0].plot([pos[0] for pos in self.spline_poss], label='spline pos') if spline_poss is not None else None\n",
    "            axs[0, 0].plot([pos[0] for pos in self.state_poss], label='state pos')\n",
    "            axs[0, 0].set_ylabel(f\"x pos\")\n",
    "            axs[0, 0].legend()\n",
    "            axs[0, 0].grid()\n",
    "\n",
    "            axs[1, 0].plot([pos[1] for pos in self.spline_poss], label='spline pos') if spline_poss is not None else None\n",
    "            axs[1, 0].plot([pos[1] for pos in self.state_poss], label='state pos')\n",
    "            axs[1, 0].set_ylabel(f\"y pos\")\n",
    "            axs[1, 0].legend()\n",
    "            axs[1, 0].grid()\n",
    "\n",
    "            axs[2, 0].plot([pos[2] for pos in self.spline_poss], label='spline pos') if spline_poss is not None else None\n",
    "            axs[2, 0].plot([pos[2] for pos in self.state_poss], label='state pos')\n",
    "            axs[2, 0].set_ylabel(f\"z pos\")\n",
    "            axs[2, 0].legend()\n",
    "            axs[2, 0].grid()\n",
    "\n",
    "            axs[0, 1].plot([cmd.velocity[0] for cmd in self.vision_commands], label='pred', marker='.') if self.vision_based else None\n",
    "            axs[0, 1].plot([cmd.velocity[0] for cmd in self.expert_commands], label='cmd') if self.expert_command is not None else None\n",
    "            axs[0, 1].plot([vel[0] for vel in self.spline_vels], label='spline vel') if spline_vels is not None else None\n",
    "            axs[0, 1].plot([vel[0] for vel in self.state_vels], label='state vel')\n",
    "            axs[0, 1].set_ylabel(f\"x vel\")\n",
    "            axs[0, 1].legend()\n",
    "            axs[0, 1].grid()\n",
    "\n",
    "            axs[1, 1].plot([cmd.velocity[1] for cmd in self.vision_commands], label='pred', marker='.') if self.vision_based else None\n",
    "            axs[1, 1].plot([cmd.velocity[1] for cmd in self.expert_commands], label='cmd') if self.expert_command is not None else None\n",
    "            axs[1, 1].plot([vel[1] for vel in self.spline_vels], label='spline vel') if spline_vels is not None else None\n",
    "            axs[1, 1].plot([vel[1] for vel in self.state_vels], label='state vel')\n",
    "            axs[1, 1].set_ylabel(f\"y vel\")\n",
    "            axs[1, 1].legend()\n",
    "            axs[1, 1].grid()\n",
    "\n",
    "            axs[2, 1].plot([cmd.velocity[2] for cmd in self.vision_commands], label='pred', marker='.') if self.vision_based else None\n",
    "            axs[2, 1].plot([cmd.velocity[2] for cmd in self.expert_commands], label='cmd') if self.expert_command is not None else None\n",
    "            axs[2, 1].plot([vel[2] for vel in self.spline_vels], label='spline vel') if spline_vels is not None else None\n",
    "            axs[2, 1].plot([vel[2] for vel in self.state_vels], label='state vel')\n",
    "            axs[2, 1].set_ylabel(f\"z vel\")\n",
    "            axs[2, 1].legend()\n",
    "            axs[2, 1].grid()\n",
    "\n",
    "            fig.savefig(f\"{self.folder}/cmd_plot.png\")\n",
    "\n",
    "            self.logger.debug(f'Saving plotted commands figure')\n",
    "\n",
    "            # clear and delete fig\n",
    "            plt.clf()\n",
    "            plt.close(fig)\n",
    "\n",
    "            self.logger.debug(f'Closed figure')\n",
    "\n",
    "            self.plotted_commands = True\n",
    "\n",
    "        # save collected evims\n",
    "        if self.state is not None and self.state.pos[0] > self.data_collection_xrange[1] and self.save_events and not self.saved_events:\n",
    "            self.logger.debug(f'Saving evims as npy file')\n",
    "            np.save(f\"{self.folder}/evims.npy\", self.evims)\n",
    "            self.logger.debug(f'Saving evims to {self.folder}/evims.npy done')\n",
    "            self.saved_events = True\n",
    "\n",
    "        # save collected im_dbg2s\n",
    "        if self.state is not None and self.state.pos[0] > self.data_collection_xrange[1] and self.save_im_dbg2 and not self.saved_im_dbg2:\n",
    "            self.logger.debug(f'Saving im_dbg2s as npy file')\n",
    "            np.save(f\"{self.folder}/im_dbg2s.npy\", self.im_dbg2s)\n",
    "            self.logger.debug(f'Saving im_dbg2s to {self.folder}/im_dbg2s.npy done')\n",
    "            self.saved_im_dbg2 = True\n",
    "\n",
    "    #### END OBSERVATION_CALLBACK\n",
    "\n",
    "    def log_data(self, log_expert=False):\n",
    "\n",
    "        # get the current time stamp\n",
    "        # NOTE use image timestamp since this is important for calculating events\n",
    "        # and we are using approximate time syncing\n",
    "        timestamp = np.round(self.im_t, 3)\n",
    "\n",
    "        data_entry = [\n",
    "                        timestamp,\n",
    "                        self.desiredVel,\n",
    "                        self.state.att[0],\n",
    "                        self.state.att[1],\n",
    "                        self.state.att[2],\n",
    "                        self.state.att[3],\n",
    "                        self.state.pos[0],\n",
    "                        self.state.pos[1],\n",
    "                        self.state.pos[2],\n",
    "                        self.state.vel[0],\n",
    "                        self.state.vel[1],\n",
    "                        self.state.vel[2],\n",
    "                        self.command.velocity[0] if not log_expert else self.expert_command.velocity[0],\n",
    "                        self.command.velocity[1] if not log_expert else self.expert_command.velocity[1],\n",
    "                        self.command.velocity[2] if not log_expert else self.expert_command.velocity[2],\n",
    "                        self.current_cmd_controller.collective_thrust,\n",
    "                        self.current_cmd_controller.bodyrates.x,\n",
    "                        self.current_cmd_controller.bodyrates.y,\n",
    "                        self.current_cmd_controller.bodyrates.z,\n",
    "                        self.col,\n",
    "                        ]\n",
    "\n",
    "        new_row = pd.DataFrame([data_entry], columns=self.data_buffer.columns)\n",
    "        self.data_buffer = pd.concat([self.data_buffer, new_row], ignore_index=True)\n",
    "\n",
    "        # append data to csv file every data_buffer_maxlength entries\n",
    "        if len(self.data_buffer) >= self.data_buffer_maxlength:\n",
    "            self.data_buffer.to_csv(opj(self.folder, 'data.csv'), mode='a', header=not self.first_data_write, index=True)\n",
    "            self.data_buffer = pd.DataFrame(self.data_format)\n",
    "            self.first_data_write = True\n",
    "\n",
    "        # write images every log call\n",
    "        cv2.imwrite(f\"{self.folder}/{timestamp:.3f}_im.png\", (self.im*255).astype(np.uint8))\n",
    "        cv2.imwrite(f\"{self.folder}/{timestamp:.3f}_depth.png\", (self.depth*255).astype(np.uint8))\n",
    "\n",
    "        # if self.save_events and not self.saved_events:\n",
    "        #     self.evims.append(self.events)\n",
    "\n",
    "        # if self.save_im_dbg2 and not self.saved_im_dbg2:\n",
    "        #     self.im_dbg2s.append(self.im_dbg2)\n",
    "\n",
    "    def fix_corrupted_depth(self, depth_image, neighbors=5):\n",
    "        corrupted_indices = np.where(depth_image == 0.0)\n",
    "        if len(corrupted_indices) == 0:\n",
    "            return depth_image\n",
    "        \n",
    "        # Iterate through each corrupted pixel\n",
    "        for i in range(len(corrupted_indices[0])):\n",
    "            row, col = corrupted_indices[0][i], corrupted_indices[1][i]\n",
    "\n",
    "            # Extract the neighborhood around the corrupted pixel\n",
    "            neighborhood = depth_image[max(0, row - neighbors):min(depth_image.shape[0], row + neighbors + 1),\n",
    "                                    max(0, col - neighbors):min(depth_image.shape[1], col + neighbors + 1)]\n",
    "\n",
    "            # Exclude the corrupted pixel itself (center of the neighborhood)\n",
    "            neighborhood = neighborhood[neighborhood != 0.0]\n",
    "\n",
    "            # Interpolate the corrupted pixel value as the mean of its neighbors\n",
    "            interpolated_value = np.mean(neighborhood)\n",
    "\n",
    "            # Assign the interpolated value to the corrupted pixel\n",
    "            depth_image[row, col] = interpolated_value\n",
    "\n",
    "        return depth_image\n",
    "\n",
    "    def state_callback(self, state_data):\n",
    "        self.state = AgileQuadState(state_data)\n",
    "        try:\n",
    "            self.col = self.if_collide(self.obs_msg.obstacles[0])\n",
    "        except:\n",
    "            self.col = 0\n",
    "\n",
    "    def im_callback(self, im_msg):\n",
    "\n",
    "        # legacy\n",
    "        # if self.image_w is None or self.image_h is None:\n",
    "            # take these values from the config file instead\n",
    "            # self.image_w = im_msg.width\n",
    "            # self.image_h = im_msg.height\n",
    "\n",
    "        try:\n",
    "            im = self.cv_bridge.imgmsg_to_cv2(im_msg, 'bgr8')\n",
    "        except CvBridgeError as e:\n",
    "            rospy.logerr(\"[IM_CALLBACK] CvBridge Error: {0}\".format(e))\n",
    "            return -1\n",
    "        \n",
    "        self.im_ctr += 1\n",
    "        im_t = im_msg.header.stamp.to_nsec() / 1e9 # float with 9 digits past decimal\n",
    "        self.prev_t = np.round(self.im_t, 3)\n",
    "        self.im_t = np.round(im_t,3)\n",
    "        # for rgb images, convert to normalized single channel,\n",
    "        # preferably in the same way as Vid2E\n",
    "        if len(im.shape) == 3 or im.shape[2] == 3:\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "            im = im.astype(np.float32)/255.0\n",
    "        else:\n",
    "            im = im.astype(np.float32)\n",
    "        # save image\n",
    "        self.prev_im = self.im\n",
    "        self.im = im\n",
    "\n",
    "        if self.do_events:\n",
    "            # compute event batch\n",
    "            self.compute_events(gimbal=False)\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def depth_callback(self, depth_msg):\n",
    "\n",
    "        if self.image_w is None or self.image_h is None:\n",
    "            self.image_w = depth_msg.width\n",
    "            self.image_h = depth_msg.height\n",
    "        try:\n",
    "            im = self.cv_bridge.imgmsg_to_cv2(depth_msg, 'passthrough')\n",
    "        except CvBridgeError as e:\n",
    "            rospy.logerr(\"[DEPTH_CALLBACK] CvBridge Error: {0}\".format(e))\n",
    "            return -1\n",
    "        \n",
    "        self.depth_t = depth_msg.header.stamp.to_nsec()/1e9\n",
    "        im = np.clip(im / self.depth_im_threshold, 0, 1)\n",
    "\n",
    "        self.depth = self.fix_corrupted_depth(im)\n",
    "        \n",
    "        # legacy\n",
    "        # # compute gimbaled images and save\n",
    "        # q = np.array([self.state.att[0], self.state.att[1], self.state.att[2], self.state.att[3]])\n",
    "        # self.depth_gimbal, self.pts = self.gimbal.do_gimbal(self.depth, q, self.gimbal_w, self.gimbal_h, do_clip=True)\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def obstacle_callback(self, obs_data):\n",
    "        self.obs_msg = obs_data\n",
    "\n",
    "    def if_collide(self, obs):\n",
    "        \"\"\"\n",
    "        Borrowed and modified from evaluation_node\n",
    "        \"\"\"\n",
    "\n",
    "        if self.is_trees:\n",
    "            dist = np.linalg.norm(np.array([obs.position.x, obs.position.y]))\n",
    "        else:\n",
    "            dist = np.linalg.norm(np.array([obs.position.x, obs.position.y, obs.position.z]))\n",
    "        # margin is distance to object center minus object radius minus drone radius (estimated)\n",
    "        margin = dist - obs.scale\n",
    "        # Ground hit condition\n",
    "        if margin < 0 or self.state.pos[2] <= 0.1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def publish_command(self, command):\n",
    "        if command.mode == AgileCommandMode.SRT:\n",
    "            assert len(command.rotor_thrusts) == 4\n",
    "            cmd_msg = Command()\n",
    "            cmd_msg.t = command.t\n",
    "            cmd_msg.header.stamp = rospy.Time(command.t)\n",
    "            cmd_msg.is_single_rotor_thrust = True\n",
    "            cmd_msg.thrusts = command.rotor_thrusts\n",
    "            if self.publish_commands:\n",
    "                self.cmd_pub.publish(cmd_msg)\n",
    "                return\n",
    "        elif command.mode == AgileCommandMode.CTBR:\n",
    "            assert len(command.bodyrates) == 3\n",
    "            cmd_msg = Command()\n",
    "            cmd_msg.t = command.t\n",
    "            cmd_msg.header.stamp = rospy.Time(command.t)\n",
    "            cmd_msg.is_single_rotor_thrust = False\n",
    "            cmd_msg.collective_thrust = command.collective_thrust\n",
    "            cmd_msg.bodyrates.x = command.bodyrates[0]\n",
    "            cmd_msg.bodyrates.y = command.bodyrates[1]\n",
    "            cmd_msg.bodyrates.z = command.bodyrates[2]\n",
    "            if self.publish_commands:\n",
    "                self.cmd_pub.publish(cmd_msg)\n",
    "                return\n",
    "        elif command.mode == AgileCommandMode.LINVEL:\n",
    "            vel_msg = TwistStamped()\n",
    "            vel_msg.header.stamp = rospy.Time(command.t)\n",
    "            vel_msg.twist.linear.x = command.velocity[0]\n",
    "            vel_msg.twist.linear.y = command.velocity[1]\n",
    "            vel_msg.twist.linear.z = command.velocity[2]\n",
    "            vel_msg.twist.angular.x = 0.0\n",
    "            vel_msg.twist.angular.y = 0.0\n",
    "            vel_msg.twist.angular.z = command.yawrate\n",
    "            if self.publish_commands:\n",
    "                self.linvel_pub.publish(vel_msg)\n",
    "                return\n",
    "        else:\n",
    "            assert False, \"Unknown command mode specified\"\n",
    "\n",
    "    def start_callback(self, data):\n",
    "        self.logger.info(\"Start publishing commands!\")\n",
    "        self.publish_commands = True\n",
    "\n",
    "    def create_obstacle(self):\n",
    "        # Create an obstacle with specified position and scale\n",
    "        obs = Obstacle()\n",
    "        obs.position = Vector3(1000, 1000, 1000)\n",
    "        obs.scale = 0.5\n",
    "        return obs\n",
    "\n",
    "    def create_obstacle_array(self):\n",
    "        # Create an ObstacleArray message\n",
    "        obs_array = ObstacleArray()\n",
    "        obs_array.header = Header()\n",
    "        obs_array.header.stamp = rospy.Time.now()\n",
    "        obs_array.t = rospy.get_time()  # Current time as float64\n",
    "        obs_array.num = 10  # Number of obstacles\n",
    "\n",
    "        # Create 10 obstacles and add to the obstacle array\n",
    "        for _ in range(10):\n",
    "            obs = self.create_obstacle()\n",
    "            obs_array.obstacles.append(obs)\n",
    "\n",
    "        return obs_array\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_cfg = OmegaConf.load(opj(base_path2, \"configs/sim_config.yaml\")) # type: ignore\n",
    "    run_cfg.exp_name = datetime.now().strftime('%Y_%m_%d__%H_%M_%S')\n",
    "    cli_cfg = OmegaConf.from_cli(sys.argv[1:])\n",
    "    run_cfg = OmegaConf.merge(run_cfg, cli_cfg)\n",
    "    #agile_pilot_node = AgilePilotNode(vision_based=args.vision_based, ppo_path=args.ppo_path, model_type=args.model_type, model_path=args.model_path, num_recurrent=args.num_recurrent, keyboard=args.keyboard, use_planner=False, exp_name=args.exp_name, total_num_exps=args.total_num_exps)\n",
    "    agile_pilot_node = AgilePilotNode(run_cfg)\n",
    "    rospy.spin()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fly_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
